start_time,end_time,speaker,title,abstract,bio,expandable
10:00,10:40,Shay Moran,What Is The Sample Complexity of Differentially Private Learning?,"In differentially private learning there are two main definitions: ""Realizable Private PAC Learning"" and ""Agnostic Private PAC Learning"". This talk explores a quantitative question: What is the sample complexity of private learning?\n\nThe realizable setting has essentially been resolved following a sequence of works, and we now know that the sample complexity is Theta(log|C|) where C is the concept class. In the more challenging agnostic setting, however, there is still a significant gap, with the upper bound being O(log|C|) and the lower bound being Omega(d), where d is the VC dimension of C. I will discuss an approach to improve the known upper bound for specific classes, by finding explicit constructions of certain coverings. I'll describe a construction for the class of decision lists, which improves upon the best known (but non-explicit) construction, and implies an O(d log d) upper bound for the agnostic private sample complexity of decision lists.","Shay Moran is an assistant professor at the Technion. His research interests include computational learning theory, information theory, and combinatorics.",TRUE
10:40,10:55,Hilla Schefler,A General 'Private Learning Implies Online Learning' Theorem,"We prove a black-box reduction from private learning to online learning, demonstrating that every privately learnable concept class is online learnable. Specifically, we reduce properly private learning a concept class with approximate DP to proper online learning the same class in the realizable mistake-bound model. This generalizes previous results that relied on specific private learners or restricted to specific concept classes. Our approach combines the sample compression framework with Ben-David and Dichterman's partial-concept learning model, introducing a conversion mechanism from sample compression schemes to online learners. This allows us to leverage Bun et al.'s recent result that private learnability implies the existence of a small sample compression.","Hilla Schefler is a PhD student at the Technion, working with Prof. Shay Moran. Her research focuses on the connections between privacy, learnability, and compression.",TRUE
10:55,11:10,Bogdan Chornomaz,Topological barrier to replicable learning,"Replicable learning ensures that with high probability, a learning algorithm produces similar predictions across multiple runs on similar datasets. Current approaches use randomization in training to achieve differential privacy guarantees, but this introduces a tradeoff between accuracy and replicability. In this talk, we'll explore a fundamental topological barrier that shows replicable learning is impossible for any non-trivial hypothesis class without assumptions about the data distribution. We prove that for every non-trivial hypothesis class, there exists a data distribution where uniform convergence occurs but replicable learning is impossible. This generalizes recent results by Bun et al. (2020) on private learning and establishes that distribution assumptions are necessary for replicable learning.",Bogdan Chornomaz is a PhD candidate working on the theoretical foundations of machine learning. His research focuses on exploring fundamental limitations and possibilities in learning algorithms.,TRUE
11:10,11:35,,Coffee Break,,,FALSE
11:35,12:15,Yishay Mansour,A Theory of Interpretable Approximations,"As AI systems become more widespread, there's an increasing need for models that are both accurate and interpretable. In this talk, I'll present a theoretical framework for analyzing the tradeoff between these competing objectives. We formalize the problem of approximating a complex, accurate model (such as a neural network) with a simpler, interpretable one (like a decision tree). Our main result characterizes the minimum approximation error achievable for any interpretable hypothesis class with VC dimension d when approximating functions from a more complex class. We establish both upper and lower bounds on this error, which match up to logarithmic factors. I'll discuss applications of this theory to specific interpretable classes and show how it provides formal guarantees for model distillation and knowledge transfer.","Yishay Mansour is a Professor at Tel Aviv University and a Research Scientist at Google. His research focuses on machine learning theory, multi-agent systems, and algorithmic game theory. He has made significant contributions to boosting algorithms, online learning, and reinforcement learning.",TRUE
12:15,12:30,Tal Herman,Verifying The Unseen: Interactive Proofs for Distribution Properties,"We present a novel approach to test properties of probability distributions when the verifier has limited access to samples. Using interactive proofs, we develop protocols where a prover can convince a verifier that a distribution has certain properties, even when the verifier cannot directly sample enough data points to verify this independently. We demonstrate efficient interactive proofs for several fundamental distribution properties, including entropy approximation and distribution similarity testing. Our protocols allow the verifier to use exponentially fewer samples than would be required without a prover, while maintaining soundness against computationally unbounded provers.","Tal Herman is a graduate student at the Hebrew University of Jerusalem, working on theoretical computer science with a focus on interactive proof systems and property testing.",TRUE
12:30,12:45,Tomer Shoham,Differential privacy and hypothesis testing - from parametric testing to ECDFs,"This talk explores the intersection of differential privacy (DP) and hypothesis testing, examining how to perform valid statistical tests while preserving privacy. I'll first cover our work on DP parametric tests, showing how to construct private analogues for common tests like t-tests and chi-squared tests. Then I'll discuss our more recent research on privately comparing entire distributions using empirical cumulative distribution functions (ECDFs). We've developed methods to privately estimate the Kolmogorov-Smirnov distance between distributions and construct confidence bands for ECDFs, with theoretical guarantees on both privacy and statistical validity.",Tomer Shoham is a researcher focusing on statistical methods for privacy-preserving data analysis. His work develops techniques that balance rigorous privacy protections with statistical utility.,TRUE
12:45,13:00,Moshe Shenfeld,Understanding Generalization via a Bayes Factor,"Why do complex models like neural networks generalize well despite being able to fit random data? This talk presents a new perspective on generalization using the Bayes factor, a Bayesian model comparison tool. We propose that generalization occurs when a model's fit to the true pattern is significantly better than its fit to random patterns. This approach formalizes Occam's razor within modern machine learning, providing a quantitative measure that predicts when a model will generalize well. Unlike traditional complexity measures, our Bayesian measure explains why neural networks can be both expressive enough to fit random data yet still generalize well on structured data.","Moshe Shenfeld is a PhD student at the Hebrew University of Jerusalem, working with Prof. Katrina Ligett. His research explores the theoretical foundations of machine learning, focusing on generalization, privacy, and fairness.",TRUE
13:00,14:20,,Lunch,,,FALSE
14:20,15:00,Edith Cohen,Hot PATE: Private Aggregation of Distributions for Diverse Tasks,"This talk introduces Hot PATE, a novel framework for private aggregation of teacher distributions in teacher-student models. Traditional PATE frameworks primarily support classification tasks with a common label space across all teachers. Hot PATE generalizes this approach to support diverse prediction tasks, including regression and multi-task learning, by aggregating the distribution parameters rather than the predictions themselves. We'll cover the theoretical guarantees of our approach and demonstrate empirical results showing that Hot PATE maintains high utility while preserving differential privacy across various machine learning tasks.","Edith Cohen is a researcher at Google and a visiting professor at Tel Aviv University. Her research interests include algorithms for big data, privacy, and machine learning systems.",TRUE
15:00,15:20,Adi Haviv,Not Every Image is Worth a Thousand Words: Quantifying Originality in Stable Diffusion,"Large text-to-image models like Stable Diffusion have demonstrated remarkable capabilities, but questions remain about how much they simply reproduce their training data versus creating truly novel imagery. This talk presents methods for quantifying the originality of images generated by these models. We introduce metrics to measure memorization and replication, analyze factors that influence originality, and demonstrate how prompt design can affect whether outputs are novel combinations of concepts or near-duplicates of training examples. Our findings have implications for understanding the creative capabilities of generative models and addressing copyright concerns.","Adi Haviv is a graduate student at the Weizmann Institute of Science, researching the intersection of machine learning, creativity, and intellectual property. Her work focuses on understanding and evaluating generative AI systems.",TRUE
15:20,16:00,Ran Canetti,Co-Designing the Pilot Release of Israel's National Registry of Live Births: Reconciling Privacy with Accuracy and Usability,"The Israeli Central Bureau of Statistics (ICBS) is launching a pilot program to make the National Registry of Live Births available to researchers while preserving privacy. This talk presents our collaborative effort to design a privacy system that balances utility, privacy, and practicality. We'll discuss the unique challenges of working with sensitive birth records, the differential privacy mechanisms we've implemented, and the process of co-designing a system with government stakeholders who have varying technical backgrounds. I'll share key lessons learned about translating theoretical privacy guarantees into real-world implementations that meet the needs of both data stewards and researchers.","Ran Canetti is a Professor of Computer Science at Boston University and the Director of the BU Center for Reliable Information Systems & Cyber Security. His research focuses on cryptography and computer security, with recent work on privacy-preserving techniques for statistical databases.",TRUE